# Word2Vec-Embedding : CBOW
An implementation of CBOW (Continuous Bag of Words) model for word embeddings.
The repository contains a CBOW.py file containing the class CBOW with methods to train the model, and a demo notebook of how to use the model.


## Word Embedding
Word embedding is a technique used in natural language processing (NLP) to represent words as dense vectors of real numbers, typically in a high-dimensional space. These embeddings capture semantic relationships between words based on their context in a corpus of text.

The key idea behind word embeddings is that words with similar meanings or usage patterns are mapped to nearby points in the embedding space. This allows algorithms to capture semantic similarities and relationships between words, enabling better performance in various NLP tasks such as sentiment analysis, machine translation, and named entity recognition.

## CBOW
Continuous Bag of Words (CBOW) is a model used in natural language processing (NLP) for generating word embeddings. The CBOW model predicts a target word based on its context, which consists of the surrounding words in a sentence or text window. 
![output-onlinepngtools](https://github.com/AdnaneMaj/Word2Vec-Embedding/assets/52354033/0ed23d06-7846-4ea0-b877-325120c5678a)
